{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 2- Training a Support Vector Machine (SVM) model for classifying the location based on the Received Signal Strength (RSS) from different Wi-Fi access points **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Importing libraries\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Importing the dataset\n",
    "#Download the dataset as a CSV file and store in the local directory. \n",
    "#To read data from CSV file, the simplest way is to use read_csv method of the pandas library. \n",
    "wifidata = pd.read_csv(\"wifi_data_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the data:\n",
      "(1860, 10)\n",
      "\n",
      "First few records:\n",
      "   UoM_Wireless1  UoM_Wireless6  UoM_Wireless11  eduroam1  eduroam6  \\\n",
      "0           -100            -72             -71      -100       -71   \n",
      "1           -100            -54             -90      -100       -53   \n",
      "2           -100            -83             -90      -100       -84   \n",
      "3           -100           -100            -100      -100      -100   \n",
      "4           -100            -75             -83      -100       -67   \n",
      "\n",
      "   eduroam11  Jungle Book10  PROLINK_H5004NK_8766E11  UNIC-wifi11  id  \n",
      "0        -75           -100                     -100         -100   5  \n",
      "1       -100            -84                      -63         -100   1  \n",
      "2        -88            -90                     -100         -100   2  \n",
      "3       -100           -100                     -100         -100   3  \n",
      "4       -100           -100                     -100         -100   7  \n"
     ]
    }
   ],
   "source": [
    "# 3. Exploratory Data Analysis\n",
    "#check the dimensions of the data and see first few records\n",
    "print(\"Dimensions of the data:\")\n",
    "print(wifidata.shape)\n",
    "print(\"\\nFirst few records:\")\n",
    "print(wifidata.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Data Preprocessing\n",
    "# To divide the data into attributes and labels\n",
    "X = wifidata.drop('id', axis=1)  #contains attributes\n",
    "y = wifidata['id'] # contains coresponding labels\n",
    "\n",
    "#divide data into training and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 5. Training the Algorithm\n",
    "reg = LogisticRegression().fit(X, y)\n",
    "#svclassifier = SVC(kernel='linear')  \n",
    "#svclassifier.fit(X_train, y_train) # train the algorithm on the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Making Predictions\n",
    "X_test\n",
    "y_pred = reg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[65  0  0  0  0  0  0  0]\n",
      " [ 0 39  0  0  1  0  1  0]\n",
      " [ 0  0 55  0  0  0  0  0]\n",
      " [ 0  0  1 27  0  1  0  5]\n",
      " [ 1  0  1  0 32  0  3  0]\n",
      " [ 0  0  2  0  0 57  0  0]\n",
      " [ 0  0  0  0  1  0 53  0]\n",
      " [ 0  0  0  1  0  2  0 24]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.98      1.00      0.99        65\n",
      "           2       1.00      0.95      0.97        41\n",
      "           3       0.93      1.00      0.96        55\n",
      "           4       0.96      0.79      0.87        34\n",
      "           5       0.94      0.86      0.90        37\n",
      "           6       0.95      0.97      0.96        59\n",
      "           7       0.93      0.98      0.95        54\n",
      "           8       0.83      0.89      0.86        27\n",
      "\n",
      "    accuracy                           0.95       372\n",
      "   macro avg       0.94      0.93      0.93       372\n",
      "weighted avg       0.95      0.95      0.95       372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7. Evaluating the Algorithm\n",
    "#Confusion matrix, precision, recall, and F1 measures are the most commonly used metrics for classification tasks.\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test,y_pred)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.62%\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unknown Data Labels\n",
      "[7 4 2 3 6 1 4 5 7 6 2 6 3 1 5 7 4 6 2 1 8 3 7 7 4 6 2 1 5 3 4 7 3 2 4 1 5\n",
      " 3 7 8 6 1 2 5 4 7 3 6 4 1 2 5 7 4 3 6 1 2 5 6 3 3 4 6 1 2 5 2 6 3 1 4 2 5\n",
      " 7 6 1 3 5 2 7 4 6 1 3 5 2 7 4 1 6 5 3 2 3 6 1 4 5 3 2 2 6 1 5 7 2 4 3 6 1\n",
      " 2 7 2 3 4 6 1 7 2 3 6 5 4 1 5 7 2 3 6 1 5 4 7 2 6 3 1 5 7 2 4 6 1 3 7 5 4\n",
      " 6 4 1 5 3 7 7 3 1 4 7 7 3 6 2 1 5 7 3 4 2 6 1 7 7 3 6 3 4 1 5 2 3 6 2 4 1\n",
      " 5 7 6 3 2 1 8 7 5 6 2 3 1 5 7 4 6 2 3 1 5 6 4 2 3 1 5 6 2 5 1 3 4 6 7 1 3\n",
      " 4 6 5 2 7 5 1 3 4 6 2 7 5 1 3 6 2 4 7 5 1 3 4 7 2 5 1 4 6 3 2 5 1 4 4 3 3\n",
      " 2 1 5 4 3 4 3 5 2 7 7 7 1 6 4 7 5 3 2 1 6 7 7 4 8 1 2 3 4 6 5 7 1 2 3 8 6\n",
      " 4 5 7 1]\n"
     ]
    }
   ],
   "source": [
    "# 8. Predict the locations of Unknown Data\n",
    "\n",
    "# Read the unknown data from \"unknown_data.csv\". \n",
    "# Please make sure to have that file within the local directory or add the correct path to the file\n",
    "unknowndata= pd.read_csv(\"wifi_data_test1.csv\")\n",
    "unknowndata = unknowndata.drop(columns=['id'])\n",
    "unknown_pred = reg.predict(unknowndata)\n",
    "print(\"\\nUnknown Data Labels\")\n",
    "print(unknown_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "feature_values_for_single_data_point = [-100,-71,-75,-100,-100,-100,-100,-100,-100]\n",
    "single_data_point_features = [feature_values_for_single_data_point]  # Replace with your actual feature values\n",
    "predicted_class = reg.predict(single_data_point_features)\n",
    "print(predicted_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
